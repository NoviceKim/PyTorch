{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " All of TorchVision datasets include 2 factors\n",
    " - transform: to transform sample data\n",
    " - target_transform: to transform target data\n",
    "'''\n",
    "\n",
    "# import Train Data from FashionMNIST\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# import Test Data from FashionMNIST\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader for train, test data\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, Channel, Height, Width]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n",
      "Data Type of y: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Check the output shape of DataLoader\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, Channel, Height, Width]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    print(f\"Data Type of y: {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Before start training, check the device to train\n",
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available()\n",
    "                else \"CPU\")\n",
    "\n",
    "print(f\"Current Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=18, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Declare NeuralNetwork class based on nn.Module\n",
    "class NeuralNetwork(nn.Module):\n",
    "    # This will execute when the class object is called\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Execute nn.Module\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Neural Network Stack\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # Linear - The number of output features must be same as the number of input features on next Linear process\n",
    "            nn.ReLU(),  # Activation Function\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 18)\n",
    "        )\n",
    "    # Declare how to send the data to the Neural Network\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# Pass the Neural Network computing to available device to accelerate the process\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()     # Loss function - Cross Entropy\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)    # Optimizer - SGD (Stochastic Gradient Descent) with 0.001 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training Function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)     # Predict the train data with model\n",
    "        loss = loss_fn(pred, y)     # Calculate loss of model prediction\n",
    "\n",
    "        loss.backward()     # Back Propagation\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()   # Initialize gradient before the next epoch\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Loss: {loss:>7f} [{current:>5d} / {size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()    # Evaluate the model\n",
    "\n",
    "    test_loss, correct = 0, 0   # Initialize loss and accuracy\n",
    "\n",
    "    # Initialize gradient\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            # Update loss and accuracy on every step\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct * 100):0.1f}% \\n Average Loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "---------------------------------\n",
      "Loss: 2.904298 [   64 / 60000]\n",
      "Loss: 2.857105 [ 6464 / 60000]\n",
      "Loss: 2.803376 [12864 / 60000]\n",
      "Loss: 2.770401 [19264 / 60000]\n",
      "Loss: 2.722653 [25664 / 60000]\n",
      "Loss: 2.637305 [32064 / 60000]\n",
      "Loss: 2.625305 [38464 / 60000]\n",
      "Loss: 2.527887 [44864 / 60000]\n",
      "Loss: 2.487844 [51264 / 60000]\n",
      "Loss: 2.394116 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 28.1% \n",
      " Average Loss: 2.373906 \n",
      "\n",
      "Epoch 2 \n",
      "---------------------------------\n",
      "Loss: 2.396533 [   64 / 60000]\n",
      "Loss: 2.374557 [ 6464 / 60000]\n",
      "Loss: 2.241761 [12864 / 60000]\n",
      "Loss: 2.252399 [19264 / 60000]\n",
      "Loss: 2.186473 [25664 / 60000]\n",
      "Loss: 2.054565 [32064 / 60000]\n",
      "Loss: 2.108408 [38464 / 60000]\n",
      "Loss: 1.985680 [44864 / 60000]\n",
      "Loss: 1.981410 [51264 / 60000]\n",
      "Loss: 1.865854 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 61.0% \n",
      " Average Loss: 1.871484 \n",
      "\n",
      "Epoch 3 \n",
      "---------------------------------\n",
      "Loss: 1.928869 [   64 / 60000]\n",
      "Loss: 1.885610 [ 6464 / 60000]\n",
      "Loss: 1.725300 [12864 / 60000]\n",
      "Loss: 1.760395 [19264 / 60000]\n",
      "Loss: 1.656103 [25664 / 60000]\n",
      "Loss: 1.599094 [32064 / 60000]\n",
      "Loss: 1.604807 [38464 / 60000]\n",
      "Loss: 1.513532 [44864 / 60000]\n",
      "Loss: 1.525551 [51264 / 60000]\n",
      "Loss: 1.406670 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0% \n",
      " Average Loss: 1.439451 \n",
      "\n",
      "Epoch 4 \n",
      "---------------------------------\n",
      "Loss: 1.523788 [   64 / 60000]\n",
      "Loss: 1.493090 [ 6464 / 60000]\n",
      "Loss: 1.324978 [12864 / 60000]\n",
      "Loss: 1.404176 [19264 / 60000]\n",
      "Loss: 1.293089 [25664 / 60000]\n",
      "Loss: 1.297297 [32064 / 60000]\n",
      "Loss: 1.301674 [38464 / 60000]\n",
      "Loss: 1.237413 [44864 / 60000]\n",
      "Loss: 1.265712 [51264 / 60000]\n",
      "Loss: 1.169933 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6% \n",
      " Average Loss: 1.195896 \n",
      "\n",
      "Epoch 5 \n",
      "---------------------------------\n",
      "Loss: 1.284050 [   64 / 60000]\n",
      "Loss: 1.271344 [ 6464 / 60000]\n",
      "Loss: 1.095432 [12864 / 60000]\n",
      "Loss: 1.209001 [19264 / 60000]\n",
      "Loss: 1.092666 [25664 / 60000]\n",
      "Loss: 1.119785 [32064 / 60000]\n",
      "Loss: 1.134709 [38464 / 60000]\n",
      "Loss: 1.078246 [44864 / 60000]\n",
      "Loss: 1.111843 [51264 / 60000]\n",
      "Loss: 1.035519 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0% \n",
      " Average Loss: 1.050577 \n",
      "\n",
      "Epoch 6 \n",
      "---------------------------------\n",
      "Loss: 1.131105 [   64 / 60000]\n",
      "Loss: 1.138883 [ 6464 / 60000]\n",
      "Loss: 0.949051 [12864 / 60000]\n",
      "Loss: 1.088984 [19264 / 60000]\n",
      "Loss: 0.972166 [25664 / 60000]\n",
      "Loss: 1.001406 [32064 / 60000]\n",
      "Loss: 1.032005 [38464 / 60000]\n",
      "Loss: 0.978310 [44864 / 60000]\n",
      "Loss: 1.008772 [51264 / 60000]\n",
      "Loss: 0.950245 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4% \n",
      " Average Loss: 0.955228 \n",
      "\n",
      "Epoch 7 \n",
      "---------------------------------\n",
      "Loss: 1.022030 [   64 / 60000]\n",
      "Loss: 1.051858 [ 6464 / 60000]\n",
      "Loss: 0.847987 [12864 / 60000]\n",
      "Loss: 1.007821 [19264 / 60000]\n",
      "Loss: 0.894508 [25664 / 60000]\n",
      "Loss: 0.916136 [32064 / 60000]\n",
      "Loss: 0.962462 [38464 / 60000]\n",
      "Loss: 0.913052 [44864 / 60000]\n",
      "Loss: 0.935225 [51264 / 60000]\n",
      "Loss: 0.890479 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7% \n",
      " Average Loss: 0.888223 \n",
      "\n",
      "Epoch 8 \n",
      "---------------------------------\n",
      "Loss: 0.939639 [   64 / 60000]\n",
      "Loss: 0.989570 [ 6464 / 60000]\n",
      "Loss: 0.774378 [12864 / 60000]\n",
      "Loss: 0.948766 [19264 / 60000]\n",
      "Loss: 0.840654 [25664 / 60000]\n",
      "Loss: 0.852095 [32064 / 60000]\n",
      "Loss: 0.911350 [38464 / 60000]\n",
      "Loss: 0.868706 [44864 / 60000]\n",
      "Loss: 0.880894 [51264 / 60000]\n",
      "Loss: 0.845620 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0% \n",
      " Average Loss: 0.838544 \n",
      "\n",
      "Epoch 9 \n",
      "---------------------------------\n",
      "Loss: 0.875138 [   64 / 60000]\n",
      "Loss: 0.941441 [ 6464 / 60000]\n",
      "Loss: 0.718248 [12864 / 60000]\n",
      "Loss: 0.903591 [19264 / 60000]\n",
      "Loss: 0.800376 [25664 / 60000]\n",
      "Loss: 0.803160 [32064 / 60000]\n",
      "Loss: 0.871431 [38464 / 60000]\n",
      "Loss: 0.837235 [44864 / 60000]\n",
      "Loss: 0.839502 [51264 / 60000]\n",
      "Loss: 0.810286 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 71.1% \n",
      " Average Loss: 0.799993 \n",
      "\n",
      "Epoch 10 \n",
      "---------------------------------\n",
      "Loss: 0.822876 [   64 / 60000]\n",
      "Loss: 0.901896 [ 6464 / 60000]\n",
      "Loss: 0.673776 [12864 / 60000]\n",
      "Loss: 0.867903 [19264 / 60000]\n",
      "Loss: 0.768253 [25664 / 60000]\n",
      "Loss: 0.765218 [32064 / 60000]\n",
      "Loss: 0.838315 [38464 / 60000]\n",
      "Loss: 0.813555 [44864 / 60000]\n",
      "Loss: 0.807035 [51264 / 60000]\n",
      "Loss: 0.780985 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3% \n",
      " Average Loss: 0.768825 \n",
      "\n",
      "Epoch 11 \n",
      "---------------------------------\n",
      "Loss: 0.779253 [   64 / 60000]\n",
      "Loss: 0.867868 [ 6464 / 60000]\n",
      "Loss: 0.637421 [12864 / 60000]\n",
      "Loss: 0.839033 [19264 / 60000]\n",
      "Loss: 0.741638 [25664 / 60000]\n",
      "Loss: 0.735306 [32064 / 60000]\n",
      "Loss: 0.809643 [38464 / 60000]\n",
      "Loss: 0.794451 [44864 / 60000]\n",
      "Loss: 0.780674 [51264 / 60000]\n",
      "Loss: 0.755840 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 73.6% \n",
      " Average Loss: 0.742649 \n",
      "\n",
      "Epoch 12 \n",
      "---------------------------------\n",
      "Loss: 0.741968 [   64 / 60000]\n",
      "Loss: 0.837629 [ 6464 / 60000]\n",
      "Loss: 0.606810 [12864 / 60000]\n",
      "Loss: 0.815002 [19264 / 60000]\n",
      "Loss: 0.719002 [25664 / 60000]\n",
      "Loss: 0.711021 [32064 / 60000]\n",
      "Loss: 0.783895 [38464 / 60000]\n",
      "Loss: 0.777991 [44864 / 60000]\n",
      "Loss: 0.758474 [51264 / 60000]\n",
      "Loss: 0.733586 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4% \n",
      " Average Loss: 0.719877 \n",
      "\n",
      "Epoch 13 \n",
      "---------------------------------\n",
      "Loss: 0.709418 [   64 / 60000]\n",
      "Loss: 0.810116 [ 6464 / 60000]\n",
      "Loss: 0.580469 [12864 / 60000]\n",
      "Loss: 0.794467 [19264 / 60000]\n",
      "Loss: 0.699148 [25664 / 60000]\n",
      "Loss: 0.690793 [32064 / 60000]\n",
      "Loss: 0.760256 [38464 / 60000]\n",
      "Loss: 0.763381 [44864 / 60000]\n",
      "Loss: 0.739232 [51264 / 60000]\n",
      "Loss: 0.713472 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3% \n",
      " Average Loss: 0.699515 \n",
      "\n",
      "Epoch 14 \n",
      "---------------------------------\n",
      "Loss: 0.680540 [   64 / 60000]\n",
      "Loss: 0.784558 [ 6464 / 60000]\n",
      "Loss: 0.557270 [12864 / 60000]\n",
      "Loss: 0.776485 [19264 / 60000]\n",
      "Loss: 0.681673 [25664 / 60000]\n",
      "Loss: 0.673840 [32064 / 60000]\n",
      "Loss: 0.738605 [38464 / 60000]\n",
      "Loss: 0.749945 [44864 / 60000]\n",
      "Loss: 0.722486 [51264 / 60000]\n",
      "Loss: 0.695261 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1% \n",
      " Average Loss: 0.681038 \n",
      "\n",
      "Epoch 15 \n",
      "---------------------------------\n",
      "Loss: 0.654708 [   64 / 60000]\n",
      "Loss: 0.761031 [ 6464 / 60000]\n",
      "Loss: 0.536691 [12864 / 60000]\n",
      "Loss: 0.760332 [19264 / 60000]\n",
      "Loss: 0.666409 [25664 / 60000]\n",
      "Loss: 0.659409 [32064 / 60000]\n",
      "Loss: 0.718373 [38464 / 60000]\n",
      "Loss: 0.737514 [44864 / 60000]\n",
      "Loss: 0.707891 [51264 / 60000]\n",
      "Loss: 0.678617 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8% \n",
      " Average Loss: 0.664120 \n",
      "\n",
      "Epoch 16 \n",
      "---------------------------------\n",
      "Loss: 0.631635 [   64 / 60000]\n",
      "Loss: 0.739441 [ 6464 / 60000]\n",
      "Loss: 0.518384 [12864 / 60000]\n",
      "Loss: 0.745633 [19264 / 60000]\n",
      "Loss: 0.652723 [25664 / 60000]\n",
      "Loss: 0.646820 [32064 / 60000]\n",
      "Loss: 0.699412 [38464 / 60000]\n",
      "Loss: 0.726172 [44864 / 60000]\n",
      "Loss: 0.695184 [51264 / 60000]\n",
      "Loss: 0.663343 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5% \n",
      " Average Loss: 0.648536 \n",
      "\n",
      "Epoch 17 \n",
      "---------------------------------\n",
      "Loss: 0.610857 [   64 / 60000]\n",
      "Loss: 0.719592 [ 6464 / 60000]\n",
      "Loss: 0.501958 [12864 / 60000]\n",
      "Loss: 0.732173 [19264 / 60000]\n",
      "Loss: 0.640653 [25664 / 60000]\n",
      "Loss: 0.635721 [32064 / 60000]\n",
      "Loss: 0.681741 [38464 / 60000]\n",
      "Loss: 0.715817 [44864 / 60000]\n",
      "Loss: 0.683738 [51264 / 60000]\n",
      "Loss: 0.649286 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1% \n",
      " Average Loss: 0.634115 \n",
      "\n",
      "Epoch 18 \n",
      "---------------------------------\n",
      "Loss: 0.592152 [   64 / 60000]\n",
      "Loss: 0.701402 [ 6464 / 60000]\n",
      "Loss: 0.487121 [12864 / 60000]\n",
      "Loss: 0.719663 [19264 / 60000]\n",
      "Loss: 0.629854 [25664 / 60000]\n",
      "Loss: 0.625889 [32064 / 60000]\n",
      "Loss: 0.665286 [38464 / 60000]\n",
      "Loss: 0.706718 [44864 / 60000]\n",
      "Loss: 0.673546 [51264 / 60000]\n",
      "Loss: 0.636137 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7% \n",
      " Average Loss: 0.620765 \n",
      "\n",
      "Epoch 19 \n",
      "---------------------------------\n",
      "Loss: 0.575088 [   64 / 60000]\n",
      "Loss: 0.684609 [ 6464 / 60000]\n",
      "Loss: 0.473697 [12864 / 60000]\n",
      "Loss: 0.707710 [19264 / 60000]\n",
      "Loss: 0.620248 [25664 / 60000]\n",
      "Loss: 0.617182 [32064 / 60000]\n",
      "Loss: 0.650079 [38464 / 60000]\n",
      "Loss: 0.698738 [44864 / 60000]\n",
      "Loss: 0.664682 [51264 / 60000]\n",
      "Loss: 0.623878 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2% \n",
      " Average Loss: 0.608421 \n",
      "\n",
      "Epoch 20 \n",
      "---------------------------------\n",
      "Loss: 0.559418 [   64 / 60000]\n",
      "Loss: 0.669190 [ 6464 / 60000]\n",
      "Loss: 0.461535 [12864 / 60000]\n",
      "Loss: 0.696768 [19264 / 60000]\n",
      "Loss: 0.611663 [25664 / 60000]\n",
      "Loss: 0.609366 [32064 / 60000]\n",
      "Loss: 0.636044 [38464 / 60000]\n",
      "Loss: 0.691959 [44864 / 60000]\n",
      "Loss: 0.657167 [51264 / 60000]\n",
      "Loss: 0.612379 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6% \n",
      " Average Loss: 0.597013 \n",
      "\n",
      "Epoch 21 \n",
      "---------------------------------\n",
      "Loss: 0.545049 [   64 / 60000]\n",
      "Loss: 0.655011 [ 6464 / 60000]\n",
      "Loss: 0.450445 [12864 / 60000]\n",
      "Loss: 0.686576 [19264 / 60000]\n",
      "Loss: 0.603866 [25664 / 60000]\n",
      "Loss: 0.602334 [32064 / 60000]\n",
      "Loss: 0.623086 [38464 / 60000]\n",
      "Loss: 0.686224 [44864 / 60000]\n",
      "Loss: 0.650669 [51264 / 60000]\n",
      "Loss: 0.601543 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0% \n",
      " Average Loss: 0.586476 \n",
      "\n",
      "Epoch 22 \n",
      "---------------------------------\n",
      "Loss: 0.531809 [   64 / 60000]\n",
      "Loss: 0.641894 [ 6464 / 60000]\n",
      "Loss: 0.440343 [12864 / 60000]\n",
      "Loss: 0.677079 [19264 / 60000]\n",
      "Loss: 0.596698 [25664 / 60000]\n",
      "Loss: 0.595944 [32064 / 60000]\n",
      "Loss: 0.611224 [38464 / 60000]\n",
      "Loss: 0.681457 [44864 / 60000]\n",
      "Loss: 0.645145 [51264 / 60000]\n",
      "Loss: 0.591278 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4% \n",
      " Average Loss: 0.576741 \n",
      "\n",
      "Epoch 23 \n",
      "---------------------------------\n",
      "Loss: 0.519524 [   64 / 60000]\n",
      "Loss: 0.629800 [ 6464 / 60000]\n",
      "Loss: 0.431045 [12864 / 60000]\n",
      "Loss: 0.668208 [19264 / 60000]\n",
      "Loss: 0.589853 [25664 / 60000]\n",
      "Loss: 0.590094 [32064 / 60000]\n",
      "Loss: 0.600273 [38464 / 60000]\n",
      "Loss: 0.677582 [44864 / 60000]\n",
      "Loss: 0.640478 [51264 / 60000]\n",
      "Loss: 0.581602 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7% \n",
      " Average Loss: 0.567739 \n",
      "\n",
      "Epoch 24 \n",
      "---------------------------------\n",
      "Loss: 0.508133 [   64 / 60000]\n",
      "Loss: 0.618663 [ 6464 / 60000]\n",
      "Loss: 0.422517 [12864 / 60000]\n",
      "Loss: 0.659894 [19264 / 60000]\n",
      "Loss: 0.583330 [25664 / 60000]\n",
      "Loss: 0.584723 [32064 / 60000]\n",
      "Loss: 0.590154 [38464 / 60000]\n",
      "Loss: 0.674562 [44864 / 60000]\n",
      "Loss: 0.636537 [51264 / 60000]\n",
      "Loss: 0.572455 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0% \n",
      " Average Loss: 0.559409 \n",
      "\n",
      "Epoch 25 \n",
      "---------------------------------\n",
      "Loss: 0.497505 [   64 / 60000]\n",
      "Loss: 0.608378 [ 6464 / 60000]\n",
      "Loss: 0.414698 [12864 / 60000]\n",
      "Loss: 0.652063 [19264 / 60000]\n",
      "Loss: 0.577043 [25664 / 60000]\n",
      "Loss: 0.579628 [32064 / 60000]\n",
      "Loss: 0.580786 [38464 / 60000]\n",
      "Loss: 0.672265 [44864 / 60000]\n",
      "Loss: 0.633197 [51264 / 60000]\n",
      "Loss: 0.563741 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2% \n",
      " Average Loss: 0.551697 \n",
      "\n",
      "Epoch 26 \n",
      "---------------------------------\n",
      "Loss: 0.487542 [   64 / 60000]\n",
      "Loss: 0.598813 [ 6464 / 60000]\n",
      "Loss: 0.407500 [12864 / 60000]\n",
      "Loss: 0.644624 [19264 / 60000]\n",
      "Loss: 0.571003 [25664 / 60000]\n",
      "Loss: 0.574834 [32064 / 60000]\n",
      "Loss: 0.572162 [38464 / 60000]\n",
      "Loss: 0.670604 [44864 / 60000]\n",
      "Loss: 0.630288 [51264 / 60000]\n",
      "Loss: 0.555366 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5% \n",
      " Average Loss: 0.544552 \n",
      "\n",
      "Epoch 27 \n",
      "---------------------------------\n",
      "Loss: 0.478172 [   64 / 60000]\n",
      "Loss: 0.589996 [ 6464 / 60000]\n",
      "Loss: 0.400797 [12864 / 60000]\n",
      "Loss: 0.637607 [19264 / 60000]\n",
      "Loss: 0.565090 [25664 / 60000]\n",
      "Loss: 0.570258 [32064 / 60000]\n",
      "Loss: 0.564207 [38464 / 60000]\n",
      "Loss: 0.669477 [44864 / 60000]\n",
      "Loss: 0.627820 [51264 / 60000]\n",
      "Loss: 0.547345 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7% \n",
      " Average Loss: 0.537919 \n",
      "\n",
      "Epoch 28 \n",
      "---------------------------------\n",
      "Loss: 0.469367 [   64 / 60000]\n",
      "Loss: 0.581886 [ 6464 / 60000]\n",
      "Loss: 0.394563 [12864 / 60000]\n",
      "Loss: 0.630949 [19264 / 60000]\n",
      "Loss: 0.559287 [25664 / 60000]\n",
      "Loss: 0.565893 [32064 / 60000]\n",
      "Loss: 0.556919 [38464 / 60000]\n",
      "Loss: 0.668825 [44864 / 60000]\n",
      "Loss: 0.625672 [51264 / 60000]\n",
      "Loss: 0.539598 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9% \n",
      " Average Loss: 0.531767 \n",
      "\n",
      "Epoch 29 \n",
      "---------------------------------\n",
      "Loss: 0.461034 [   64 / 60000]\n",
      "Loss: 0.574383 [ 6464 / 60000]\n",
      "Loss: 0.388812 [12864 / 60000]\n",
      "Loss: 0.624516 [19264 / 60000]\n",
      "Loss: 0.553648 [25664 / 60000]\n",
      "Loss: 0.561647 [32064 / 60000]\n",
      "Loss: 0.550212 [38464 / 60000]\n",
      "Loss: 0.668578 [44864 / 60000]\n",
      "Loss: 0.623791 [51264 / 60000]\n",
      "Loss: 0.532122 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1% \n",
      " Average Loss: 0.526051 \n",
      "\n",
      "Epoch 30 \n",
      "---------------------------------\n",
      "Loss: 0.453142 [   64 / 60000]\n",
      "Loss: 0.567388 [ 6464 / 60000]\n",
      "Loss: 0.383453 [12864 / 60000]\n",
      "Loss: 0.618345 [19264 / 60000]\n",
      "Loss: 0.548101 [25664 / 60000]\n",
      "Loss: 0.557454 [32064 / 60000]\n",
      "Loss: 0.544067 [38464 / 60000]\n",
      "Loss: 0.668592 [44864 / 60000]\n",
      "Loss: 0.622024 [51264 / 60000]\n",
      "Loss: 0.524906 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2% \n",
      " Average Loss: 0.520727 \n",
      "\n",
      "Epoch 31 \n",
      "---------------------------------\n",
      "Loss: 0.445648 [   64 / 60000]\n",
      "Loss: 0.560923 [ 6464 / 60000]\n",
      "Loss: 0.378433 [12864 / 60000]\n",
      "Loss: 0.612389 [19264 / 60000]\n",
      "Loss: 0.542659 [25664 / 60000]\n",
      "Loss: 0.553269 [32064 / 60000]\n",
      "Loss: 0.538390 [38464 / 60000]\n",
      "Loss: 0.668828 [44864 / 60000]\n",
      "Loss: 0.620347 [51264 / 60000]\n",
      "Loss: 0.518002 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4% \n",
      " Average Loss: 0.515756 \n",
      "\n",
      "Epoch 32 \n",
      "---------------------------------\n",
      "Loss: 0.438583 [   64 / 60000]\n",
      "Loss: 0.554939 [ 6464 / 60000]\n",
      "Loss: 0.373763 [12864 / 60000]\n",
      "Loss: 0.606651 [19264 / 60000]\n",
      "Loss: 0.537237 [25664 / 60000]\n",
      "Loss: 0.549012 [32064 / 60000]\n",
      "Loss: 0.533054 [38464 / 60000]\n",
      "Loss: 0.669140 [44864 / 60000]\n",
      "Loss: 0.618804 [51264 / 60000]\n",
      "Loss: 0.511374 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5% \n",
      " Average Loss: 0.511100 \n",
      "\n",
      "Epoch 33 \n",
      "---------------------------------\n",
      "Loss: 0.431874 [   64 / 60000]\n",
      "Loss: 0.549440 [ 6464 / 60000]\n",
      "Loss: 0.369374 [12864 / 60000]\n",
      "Loss: 0.601156 [19264 / 60000]\n",
      "Loss: 0.531917 [25664 / 60000]\n",
      "Loss: 0.544880 [32064 / 60000]\n",
      "Loss: 0.528209 [38464 / 60000]\n",
      "Loss: 0.669500 [44864 / 60000]\n",
      "Loss: 0.617223 [51264 / 60000]\n",
      "Loss: 0.504984 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6% \n",
      " Average Loss: 0.506749 \n",
      "\n",
      "Epoch 34 \n",
      "---------------------------------\n",
      "Loss: 0.425414 [   64 / 60000]\n",
      "Loss: 0.544366 [ 6464 / 60000]\n",
      "Loss: 0.365209 [12864 / 60000]\n",
      "Loss: 0.595822 [19264 / 60000]\n",
      "Loss: 0.526803 [25664 / 60000]\n",
      "Loss: 0.540823 [32064 / 60000]\n",
      "Loss: 0.523701 [38464 / 60000]\n",
      "Loss: 0.669860 [44864 / 60000]\n",
      "Loss: 0.615614 [51264 / 60000]\n",
      "Loss: 0.498841 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8% \n",
      " Average Loss: 0.502663 \n",
      "\n",
      "Epoch 35 \n",
      "---------------------------------\n",
      "Loss: 0.419238 [   64 / 60000]\n",
      "Loss: 0.539680 [ 6464 / 60000]\n",
      "Loss: 0.361296 [12864 / 60000]\n",
      "Loss: 0.590684 [19264 / 60000]\n",
      "Loss: 0.521821 [25664 / 60000]\n",
      "Loss: 0.536793 [32064 / 60000]\n",
      "Loss: 0.519482 [38464 / 60000]\n",
      "Loss: 0.670180 [44864 / 60000]\n",
      "Loss: 0.614020 [51264 / 60000]\n",
      "Loss: 0.492965 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9% \n",
      " Average Loss: 0.498817 \n",
      "\n",
      "Epoch 36 \n",
      "---------------------------------\n",
      "Loss: 0.413355 [   64 / 60000]\n",
      "Loss: 0.535279 [ 6464 / 60000]\n",
      "Loss: 0.357646 [12864 / 60000]\n",
      "Loss: 0.585755 [19264 / 60000]\n",
      "Loss: 0.516986 [25664 / 60000]\n",
      "Loss: 0.532817 [32064 / 60000]\n",
      "Loss: 0.515535 [38464 / 60000]\n",
      "Loss: 0.670430 [44864 / 60000]\n",
      "Loss: 0.612384 [51264 / 60000]\n",
      "Loss: 0.487392 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0% \n",
      " Average Loss: 0.495190 \n",
      "\n",
      "Epoch 37 \n",
      "---------------------------------\n",
      "Loss: 0.407724 [   64 / 60000]\n",
      "Loss: 0.531186 [ 6464 / 60000]\n",
      "Loss: 0.354210 [12864 / 60000]\n",
      "Loss: 0.581008 [19264 / 60000]\n",
      "Loss: 0.512240 [25664 / 60000]\n",
      "Loss: 0.528899 [32064 / 60000]\n",
      "Loss: 0.511807 [38464 / 60000]\n",
      "Loss: 0.670559 [44864 / 60000]\n",
      "Loss: 0.610776 [51264 / 60000]\n",
      "Loss: 0.482128 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1% \n",
      " Average Loss: 0.491762 \n",
      "\n",
      "Epoch 38 \n",
      "---------------------------------\n",
      "Loss: 0.402330 [   64 / 60000]\n",
      "Loss: 0.527337 [ 6464 / 60000]\n",
      "Loss: 0.350949 [12864 / 60000]\n",
      "Loss: 0.576410 [19264 / 60000]\n",
      "Loss: 0.507579 [25664 / 60000]\n",
      "Loss: 0.525011 [32064 / 60000]\n",
      "Loss: 0.508306 [38464 / 60000]\n",
      "Loss: 0.670600 [44864 / 60000]\n",
      "Loss: 0.609170 [51264 / 60000]\n",
      "Loss: 0.477115 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2% \n",
      " Average Loss: 0.488516 \n",
      "\n",
      "Epoch 39 \n",
      "---------------------------------\n",
      "Loss: 0.397136 [   64 / 60000]\n",
      "Loss: 0.523749 [ 6464 / 60000]\n",
      "Loss: 0.347837 [12864 / 60000]\n",
      "Loss: 0.571969 [19264 / 60000]\n",
      "Loss: 0.503054 [25664 / 60000]\n",
      "Loss: 0.521214 [32064 / 60000]\n",
      "Loss: 0.504982 [38464 / 60000]\n",
      "Loss: 0.670516 [44864 / 60000]\n",
      "Loss: 0.607562 [51264 / 60000]\n",
      "Loss: 0.472353 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3% \n",
      " Average Loss: 0.485432 \n",
      "\n",
      "Epoch 40 \n",
      "---------------------------------\n",
      "Loss: 0.392150 [   64 / 60000]\n",
      "Loss: 0.520403 [ 6464 / 60000]\n",
      "Loss: 0.344869 [12864 / 60000]\n",
      "Loss: 0.567697 [19264 / 60000]\n",
      "Loss: 0.498660 [25664 / 60000]\n",
      "Loss: 0.517510 [32064 / 60000]\n",
      "Loss: 0.501873 [38464 / 60000]\n",
      "Loss: 0.670305 [44864 / 60000]\n",
      "Loss: 0.605921 [51264 / 60000]\n",
      "Loss: 0.467835 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4% \n",
      " Average Loss: 0.482497 \n",
      "\n",
      "Epoch 41 \n",
      "---------------------------------\n",
      "Loss: 0.387367 [   64 / 60000]\n",
      "Loss: 0.517253 [ 6464 / 60000]\n",
      "Loss: 0.342047 [12864 / 60000]\n",
      "Loss: 0.563551 [19264 / 60000]\n",
      "Loss: 0.494424 [25664 / 60000]\n",
      "Loss: 0.513856 [32064 / 60000]\n",
      "Loss: 0.498897 [38464 / 60000]\n",
      "Loss: 0.669896 [44864 / 60000]\n",
      "Loss: 0.604281 [51264 / 60000]\n",
      "Loss: 0.463565 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5% \n",
      " Average Loss: 0.479698 \n",
      "\n",
      "Epoch 42 \n",
      "---------------------------------\n",
      "Loss: 0.382750 [   64 / 60000]\n",
      "Loss: 0.514306 [ 6464 / 60000]\n",
      "Loss: 0.339354 [12864 / 60000]\n",
      "Loss: 0.559575 [19264 / 60000]\n",
      "Loss: 0.490334 [25664 / 60000]\n",
      "Loss: 0.510275 [32064 / 60000]\n",
      "Loss: 0.496075 [38464 / 60000]\n",
      "Loss: 0.669339 [44864 / 60000]\n",
      "Loss: 0.602588 [51264 / 60000]\n",
      "Loss: 0.459532 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6% \n",
      " Average Loss: 0.477021 \n",
      "\n",
      "Epoch 43 \n",
      "---------------------------------\n",
      "Loss: 0.378310 [   64 / 60000]\n",
      "Loss: 0.511523 [ 6464 / 60000]\n",
      "Loss: 0.336775 [12864 / 60000]\n",
      "Loss: 0.555723 [19264 / 60000]\n",
      "Loss: 0.486381 [25664 / 60000]\n",
      "Loss: 0.506762 [32064 / 60000]\n",
      "Loss: 0.493385 [38464 / 60000]\n",
      "Loss: 0.668617 [44864 / 60000]\n",
      "Loss: 0.600844 [51264 / 60000]\n",
      "Loss: 0.455712 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7% \n",
      " Average Loss: 0.474462 \n",
      "\n",
      "Epoch 44 \n",
      "---------------------------------\n",
      "Loss: 0.374020 [   64 / 60000]\n",
      "Loss: 0.508887 [ 6464 / 60000]\n",
      "Loss: 0.334294 [12864 / 60000]\n",
      "Loss: 0.552027 [19264 / 60000]\n",
      "Loss: 0.482526 [25664 / 60000]\n",
      "Loss: 0.503407 [32064 / 60000]\n",
      "Loss: 0.490817 [38464 / 60000]\n",
      "Loss: 0.667778 [44864 / 60000]\n",
      "Loss: 0.599084 [51264 / 60000]\n",
      "Loss: 0.452076 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7% \n",
      " Average Loss: 0.472006 \n",
      "\n",
      "Epoch 45 \n",
      "---------------------------------\n",
      "Loss: 0.369860 [   64 / 60000]\n",
      "Loss: 0.506355 [ 6464 / 60000]\n",
      "Loss: 0.331909 [12864 / 60000]\n",
      "Loss: 0.548485 [19264 / 60000]\n",
      "Loss: 0.478810 [25664 / 60000]\n",
      "Loss: 0.500110 [32064 / 60000]\n",
      "Loss: 0.488348 [38464 / 60000]\n",
      "Loss: 0.666824 [44864 / 60000]\n",
      "Loss: 0.597335 [51264 / 60000]\n",
      "Loss: 0.448664 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8% \n",
      " Average Loss: 0.469649 \n",
      "\n",
      "Epoch 46 \n",
      "---------------------------------\n",
      "Loss: 0.365842 [   64 / 60000]\n",
      "Loss: 0.503966 [ 6464 / 60000]\n",
      "Loss: 0.329595 [12864 / 60000]\n",
      "Loss: 0.545085 [19264 / 60000]\n",
      "Loss: 0.475217 [25664 / 60000]\n",
      "Loss: 0.496966 [32064 / 60000]\n",
      "Loss: 0.485979 [38464 / 60000]\n",
      "Loss: 0.665726 [44864 / 60000]\n",
      "Loss: 0.595591 [51264 / 60000]\n",
      "Loss: 0.445478 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9% \n",
      " Average Loss: 0.467383 \n",
      "\n",
      "Epoch 47 \n",
      "---------------------------------\n",
      "Loss: 0.361950 [   64 / 60000]\n",
      "Loss: 0.501686 [ 6464 / 60000]\n",
      "Loss: 0.327379 [12864 / 60000]\n",
      "Loss: 0.541827 [19264 / 60000]\n",
      "Loss: 0.471692 [25664 / 60000]\n",
      "Loss: 0.493902 [32064 / 60000]\n",
      "Loss: 0.483717 [38464 / 60000]\n",
      "Loss: 0.664542 [44864 / 60000]\n",
      "Loss: 0.593853 [51264 / 60000]\n",
      "Loss: 0.442493 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0% \n",
      " Average Loss: 0.465201 \n",
      "\n",
      "Epoch 48 \n",
      "---------------------------------\n",
      "Loss: 0.358184 [   64 / 60000]\n",
      "Loss: 0.499508 [ 6464 / 60000]\n",
      "Loss: 0.325231 [12864 / 60000]\n",
      "Loss: 0.538682 [19264 / 60000]\n",
      "Loss: 0.468328 [25664 / 60000]\n",
      "Loss: 0.490977 [32064 / 60000]\n",
      "Loss: 0.481527 [38464 / 60000]\n",
      "Loss: 0.663236 [44864 / 60000]\n",
      "Loss: 0.592102 [51264 / 60000]\n",
      "Loss: 0.439690 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0% \n",
      " Average Loss: 0.463095 \n",
      "\n",
      "Epoch 49 \n",
      "---------------------------------\n",
      "Loss: 0.354508 [   64 / 60000]\n",
      "Loss: 0.497404 [ 6464 / 60000]\n",
      "Loss: 0.323172 [12864 / 60000]\n",
      "Loss: 0.535613 [19264 / 60000]\n",
      "Loss: 0.465050 [25664 / 60000]\n",
      "Loss: 0.488166 [32064 / 60000]\n",
      "Loss: 0.479358 [38464 / 60000]\n",
      "Loss: 0.661832 [44864 / 60000]\n",
      "Loss: 0.590362 [51264 / 60000]\n",
      "Loss: 0.437046 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1% \n",
      " Average Loss: 0.461061 \n",
      "\n",
      "Epoch 50 \n",
      "---------------------------------\n",
      "Loss: 0.350933 [   64 / 60000]\n",
      "Loss: 0.495393 [ 6464 / 60000]\n",
      "Loss: 0.321216 [12864 / 60000]\n",
      "Loss: 0.532672 [19264 / 60000]\n",
      "Loss: 0.461908 [25664 / 60000]\n",
      "Loss: 0.485494 [32064 / 60000]\n",
      "Loss: 0.477215 [38464 / 60000]\n",
      "Loss: 0.660395 [44864 / 60000]\n",
      "Loss: 0.588669 [51264 / 60000]\n",
      "Loss: 0.434568 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1% \n",
      " Average Loss: 0.459092 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "# Train and evaluate the model\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} \\n---------------------------------\")\n",
    "\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State as ./model/torch_basic.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"./model/torch_basic.pth\")\n",
    "print(\"Saved PyTorch Model State as ./model/torch_basic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khkim\\AppData\\Local\\Temp\\ipykernel_7160\\2919288054.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./model/torch_basic.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model state\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"./model/torch_basic.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Predict with loaded model\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
